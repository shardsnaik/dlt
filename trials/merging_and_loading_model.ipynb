{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96541935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\Rag_based_chatbot\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:39<00:00, 79.82s/it]\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "# Loading adaptor with base model and inferencing \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "adapter_path = \"C:\\\\Users\\\\Public\\\\Rag_based_chatbot\\\\Medical_bot\\\\Models\\\\lora_adapters\"  # Replace with your actual path\n",
    "configs = PeftConfig.from_pretrained(adapter_path)\n",
    "\n",
    "# Load base model (4B version)\n",
    "model_id = \"google/medgemma-4b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.float32,\n",
    "    low_cpu_usage = True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e206ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "I Had high fever. What are the potential causes?\n",
      "assistant\n",
      "Hi,It is good that you are inquiring about the fever. It is a good sign that you are taking care of yourself. The fever can be due to various inflammatory conditions. Please get the blood reports done (CBC, ESR, CRP, LFT, LFT, RFT, RTG) and consult your doctor to know the possible causes. The underlying cause can be treated with medicines. Hope this helps.\n"
     ]
    }
   ],
   "source": [
    "# Merge base model with adapters\n",
    "model = PeftModel.from_pretrained(model, adapter_path, device_map={\"\": \"cpu\"}  # Explicit CPU mapping  \n",
    "                                  )\n",
    "model = model.merge_and_unload()  # Merge adapters into base model\n",
    "\n",
    "def generate_response(prompt, max_new_tokens=512):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cpu')\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        # top_k=50,\n",
    "        # top_p=0.95\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Medical prompt example\n",
    "prompt = \"\"\"<start_of_turn>user\n",
    "I Had high fever. What are the potential causes?<end_of_turn>\n",
    "<start_of_turn>assistant\n",
    "\"\"\"\n",
    "\n",
    "print(generate_response(prompt))\n",
    "# Save merged model\n",
    "\n",
    "# takes 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69d928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Saving the model')\n",
    "merged_model_path = \"C:\\\\Users\\\\Public\\\\Rag_based_chatbot\\\\Medical_bot\\\\Models\\\\medgemma-4b-it-finetuned-merged-new\"\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "\n",
    "# Save in safetensors format\n",
    "model.save_pretrained(merged_model_path, safe_serialization=True)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5132f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cafc25e",
   "metadata": {},
   "source": [
    "### Running from merged-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10831b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Public\\\\Rag_based_chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('c://Users//Public//Rag_based_chatbot')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33184a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22928\\2087939396.py:7: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  model = AutoModelForCausalLM.from_pretrained('Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new').cpu()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_22928\\2087939396.py:8: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  tokenizer = AutoTokenizer.from_pretrained('Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new')\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# Option 1: Use raw string\n",
    "# model = AutoModelForCausalLM.from_pretrained(r'Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new').cpu()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(r'Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new')\n",
    "\n",
    "# Option 2: Use forward slashes\n",
    "model = AutoModelForCausalLM.from_pretrained('Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new').cpu()\n",
    "tokenizer = AutoTokenizer.from_pretrained('Medical_bot\\Models\\medgemma-4b-it-finetuned-merged-new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73113ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "I Had high fever. What are the potential causes?\n",
      "assistant\n",
      "Hi, As you had high fever, you may have viral or bacterial infection. Such as - Viral fever - Dengue fever - Typhoid fever - Influenza - Urinary tract infection - Ear infection - Sinus infection - Meningitis - Pneumonia - Malaria - Tuberculosis.  I would recommend you to take blood tests, urine tests, and x-ray reports to find out the exact cause of fever. You may also need to consult your doctor for proper treatment. Hope I have answered your query. Let me know if I can assist you further. Regards, Dr. Sumanth MBBS, DCH, DM\n"
     ]
    }
   ],
   "source": [
    "# Medical prompt example\n",
    "prompt = \"\"\"<start_of_turn>user\n",
    "I Had high fever. What are the potential causes?<end_of_turn>\n",
    "<start_of_turn>assistant\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to('cpu')\n",
    "outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=300,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        # top_k=50,\n",
    "        # top_p=0.95\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# takes 80min \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
